\chapter{Time Will Tell: The role of mobile learning analytics in self-regulation} 

\vfill
This longitudinal study explores the effects of tracking and monitoring time devoted to learning with a mobile tool on self-regulated learning. Graduate students (N=36) from three different online courses used their own mobile devices to track how much time they devoted to learning over a period of two to four months. Repeated measures of the Online Self-Regulated Learning Questionnaire (OSLQ) and Validity and Reliability of Time Management Questionnaire (VRTMQ) were taken along the courses. Our findings reveal positive effects of tracking time on skills/knowledge in time management. Variations in the channel, content and timing of the mobile notifications for self-reflection are investigated and time-logging patterns are described with regard to the impact of the notifications offered to students. These results not only provide evidence of the benefits of recording learning time, but also suggest relevant cues on how mobile notifications should be designed and prompted towards self-regulation of students in online courses.
\vspace{3em}

This chapter has been submitted as: 
Tabuenca, B., Kalz, M., Drachsler, H., \& Specht, M. (2015). (Submitted) Time Will Tell: The role of mobile learning analytics in self-regulated learning. \em Internet and Higher Education \em

\clearpage

\section{Introduction}
One of the main challenges in the field of Technology Enhanced Learning is the recognition of the activities and contexts of learners \citep{Kalz2014}. Lifelong learners constantly change their learning context, location, goals, environments, and also learning technologies. Lifelong learners have to combine their professional activities with learning activities and must engage simultaneously with family times to ensure a balance of adults’ responsibilities, overall wellbeing and their personal development. In this scenario a student taking part in an online course might start the day during travel with the reading of the course textbook, continue at work joining an online discussion of a specific problem during the coffee break, and finish in the evening watching video contents of the course while laid on the sofa during the commercial breaks. These short learning episodes during one day are a representative picture of lifelong learning as a whole. Learners are active in scattered moments, in different learning contexts, in different learning formats, and with different learning technologies. 
Despite a growing body of research predicting \citep{Hachey2015}, describing \citep{Wresch2005,Yang2015,Hung2008}, or providing suitable guidance on patterns of behaviour to support the learning process in online learning environments (i.e. learning management systems \citep{Brusilovsky2007} or MOOCs \citep{Gillani2014}), little is known on how students devote their time to learn across contexts beyond the boundaries of the virtual platform. 
\cite{Longworth2013} stresses the importance of lifelong learning for the twenty-first century enumerating six barriers (B1-B6) to lifelong learning as important action points to be addressed by research and developmental activities: B1) lack of personalisation; B2) time and place; B3) lack of facilities to study at home; B4) fragmentation in learning experiences; B5) health and age; B6) lack of finance. More recently, \cite{Kalz2014} mapped these barriers to technologies suggesting the adoption of \em mobile and contextualized learning\em as key solution towards dismantling barriers B1, B2, B3 and B4.
Indeed, the mobile device is probably the only artifact coexisting with the learner in all scattered learning moments and learning contexts throughout the day. Hereby, we propose using personal mobile devices to log the time devoted to learn as a suitable approach to obtain accurate measures on how do students enrolled in online courses learn independently of the material they are using (i.e. paper notes, tablet, course book, computer), independently of the location (i.e. waiting times, commuting, workplace, home) and independently of the duration of the learning session (i.e. 1 to n minutes). 

\subsection{Mobile support for self-regulated learning}
\em Learning to learn\em  is one of the eight key competences for lifelong learning \citep{EuropeanCommission2007}. It is described as the ability to pursue and persist in learning, to organise one’s own learning, including through effective management of time and information. This competence is closely bound to the concept of self-regulated learning when defined as students' proactive actions aimed at acquiring and applying information or skills that involve setting goals, self-monitoring, managing time and regulating one’s effort towards learning goal fulfilment \citep{Winne2001,Zimmerman1990}. In this manuscript personal mobile devices are instantiated as instruments to log and keep track of the time devoted to learn as a measure to foster self-regulation in online courses.
This study introduces the following features with the aim to investigate variations and best practices in mobile and contextualized learning as an approach to dismantle the barriers (B1-B4) for lifelong learning \citep{Kalz2014}:

\subsubsection{Psychology of notifications}
Recent work shows that simple notifications via SMS are useful to promote self-regulated learning \citep{Goh2012a} and reflective practice on meta-learning \citep{Tabuenca2014}. \cite{TabuencaCAA2014} propose sampling of experiences in personal mobile devices to foster awareness on personal learning preferences towards building an autobiography as a learner. The authors classify notifications based on the “timing” when the notifications can be triggered: 1) scheduled-based notifications (or interval-contingent \citep{Hektner2007}) when the notifications are triggered following a time pattern. E.g. everyday at 10 am; 2) random-based notifications (or signal-contingent), when the notifications are triggered at any moment not following a time pattern; 3) event-based notifications, when the notifications are triggered on the accomplishment of an event happened in the context of the student. I.e. the student reaches a specific location, there is a new instruction from the teacher posted at the LMS, or changing whether conditions. Likewise, the authors classified notifications according to the format of the content (i.e. text, multimedia) providing cues on which prompt fits to a specific context. More recently, two studies \citep{Tabuenca2014} analyse the effects from the variation of these variables (timing and content) on learning, envisioning a higher knowledge gain and motivation in the group of students assigned with the least complex interactions, and raising important research questions for future research on mobile notifications. Based on these conclusions, our assumption is that notifications might trigger better results in self-regulation when they are triggered in the morning (scheduled-based \citep{TabuencaCAA2014}) so students can better plan ahead their learning day in contrast to messages received in the evening or in unexpected moments throughout the day (random-based \citep{TabuencaCAA2014}). The current study therefore, postulates positive effects of sampling time-logs in self-regulation as well as a direct correlation with the timing of the notifications.
\begin{itemize}
\item H1: There is a positive relationship between logging and monitoring study-time, and self-regulation.
\item H2: Notifications delivered in the scheduled time-basis produce higher scores in self-regulation than notifications delivered on randomized time schedules.
\end{itemize}

\subsubsection{Learning analytics}
Learning analytics are driven by the collection and analysis of traces that learners leave behind \citep{Greller2012}. It can help to understand and optimise the learning process and the environments in which it occurs \citep{Siemens2011}. Until now, learning analytics are mostly feedback to the users in web-based learning dashboards \citep{Verbert2014}. Those dashboards can support raising awareness and reflection of individual and peer performance, suggest additional learning activities or content and therefore can have an impact on the learning behavior. For instance, monitoring the state in learning activity can motivate the learner towards the accomplishment of a learning goal. This cognitive process has been defined as “self monitoring”, and “understanding how to learn” \citep{Candy1991}. Personal mobile devices can be used as instruments to collect and monitor learning analytics towards self-regulation. There are little studies about mobile and ubiquitous learning analytics tools so far \citep{Fulantelli2013,Aljohani2012}. But in fact mobile devices are especially suited for self-monitoring and reflection, as the learners have them with them and can therefore reflect about their learning progress on demand and in different environments than their actual study location. 

Indeed, learning analytics can be served in every feature phone via SMS notifications, or in powerful smartphones via richer visualizations or statistics. Herby we propose the use of both channels with the aim to provide learning context to every student beyond the online learning platform. The conclusions from Tabuenca et al. \citep{Tabuenca2014} suggest that notifications fostering reflective practice should contain messages that spark the attention of the student rather than repeated messages with the same content. Indeed, the more customized the learning analytics are, the more relevant will be for student’s self-regulation. The current study therefore hypothesizes better scores in self-regulation when notifications contain feedback with learning analytics for self-regulation in contrast to notifications containing generic tips for self-regulation.
\begin{itemize}
\item H3. Notifications containing learning analytics produce higher scores in self-regulation than notifications containing generic tips for self-regulation.
\end{itemize}

\subsubsection{Seamless learning}
This study aims at facilitating a mobile tool that can be smoothly integrated by any student in his daily learning routine. The concept of seamless learning is to make the transitions between the different learning situations and context as smooth as possible \citep{Looi2010}. The proliferation of wireless-network technologies facilitates the scaffolding of seamless learning spaces as an approach for continuing learning experiences across different scenarios. The work from \cite{Tabuenca2014} stresses the significance of students’ digital competence and familiarity with mobile technology, as key aspects to take into account when sampling learning experiences on mobile devices. The diversity in competence is more notable when students have to deal with non-personal mobile devices for which the time to accomplish the learning task oscillates more remarkably. As a consequence of their results \cite{Tabuenca2014}, the authors suggest providing tools with simple interactions, using personal devices and in long-term studies. In the current research, two different mobile tools are used to investigate which patterns (or lack thereof) can be found in the way students learn and log their study-time. This study hypothesizes the following statements.
\begin{itemize}
\item H4: There are specific patterns in how students learn and log their study-time.
a) What patterns can be highlighted in the way students study and report their time?

b) Do notifications motivate students to study and report their time in the same moment they receive them? 

c) Is there any correlation between the number of time-logs, the duration of the time-logs and the final grades obtained at the final evaluation
\item H5: There is a negative correlation between the complexity of a tool for mobile learning support and the ability to integrate it in daily routines.
\end{itemize}

\section{Method}
\subsection{Participants}
A total of 89 students enrolled in online courses from two different universities in the Netherlands were invited to participate in the study. Data were collected using online forms from three different courses, namely, Psychology (C1) and two courses of Geographical Information Systems (C2 and C3 respectively). Participants in the study finally involved 36 students (17; 10; 9) that voluntarily signed the consent form, completed the pre-questionnaire and logged learning time during the course. The students recorded 1456 time-logs in the three courses: 1030 time-logs (70.74\%) in C1; 356 time-logs (24.45\%) in C2; 70 time-logs (4.80\%) in C3. The duration of the courses was 14 weeks, 9 weeks and 6 weeks respectively. 

\subsection{Materials}
The experiment has used the following tools and materials:
\subsubsection{LearnTracker Backend}
The LearnTracker Backend is accessible for the community as a cloud based solution in which teachers and instructional designers can create courses and deploy them to mobile devices. The LearnTracker Backend was released in September 2014 hosting three active courses. This system hosts and manages the master database. Additionally, the LearnTracker Backend encompasses a set of JAVA restful webservices that implement an open API with the aim to provide support across mobile clients (i.e. iOS, Android, Windows, Blackberry ...) and browsers (Chrome, Safari…). Both database and webservices are deployed and running in Google App-Engine  (GAE). The LearnTracker Backend\footnote{LearnTracker Backend. Available at http://lifelong-learning-hub.appspot.com/} is able to request and response messages in standard JSON format via HTTP (see figure \ref{fig:sload_1}).
\begin{figure}
     \centering
     \includegraphics[width=0.4\linewidth]{img/studyload_fig1}
     \caption{LearnTracker's Backend outline}
     \label{fig:sload_1}
\end{figure}

\textbf{Database model}. The LeanTracker Backend features the following tables (figure \ref{fig:sload_2}):
\begin{itemize}
\item Subject. This table includes the information that defines the yardstick (figure \ref{fig:sload_3a}) in a course. The field \em subject\_desc \em is the course identifier (e.g. “NS2322”). \em subject\_task\_desc \em  is a short description of the assignment within the course (e.g. “2.2 Geometry”),  \em subject\_task\_alternative\_desc \em  is an extended description of the assignment (e.g. “Getting to know ArcGIS and Georeferencing”),  \em subject\_task\_date\_start \em is the date in which the assignment is scheduled to start in milliseconds (e.g. “1418014800000” would be the 8th December of 2014),  \em subject\_task\_time\_duration  \em is the duration of the assignment as foreseen by the teacher in milliseconds (e.g. “7200000” would be 3 hours), \em subject\_task\_level \em is a numeric field aimed to build hierarchies within the assignments (e.g. “0” would be the most generic level in the hierarchy. “1” would be one level nested within the generic level),  \em subject\_task\_order \em is the order in which the assignments are presented in the yardstick (e.g. the item “2.2 Geometry” in figure \ref{fig:sload_3a} has order “3” in the sequence list). The records in this table are inserted when a new course is created or updated. From the course kick-off on, this table is used only for reading from the LearnTracker clients.
\item User. This table includes the information that identifies the students enrolled in a course. The field  \em subject\_desc \em  is the course identifier in which the student is enrolled  (e.g. “NS2322”), \em user\_name \em is the name of the student (e.g. “Natalia Garcia”). \em user\_type \em  is a numeric field aimed to cluster students in groups (e.g. “0” might be the control group, “1” might be the treatment group). The records in this table are only inserted when a new course is created and new students are registered for the course. From the course kick-off on, this table is used only for reading when students log in from their LearnTracker clients for the first time.
\item User. This table includes the information that identifies the students enrolled in a course. The field \em subject\_desc \em is the course identifier in which the student is enrolled  (e.g. “NS2322”),  \em user\_name \em  is the name of the student (e.g. “Natalia Garcia”).  \em user\_type \em  is a numeric field aimed to cluster students in groups (e.g. “0” might be the control group, “1” might be the treatment group). The records in this table are only inserted when a new course is created and new students are registered for the course. From the course kick-off on, this table is used only for reading when students log in from their LearnTracker clients for the first time.
\item Activity. This table hosts the timestamp and duration of the learning activity for which the students record their time. The field id\_user is the name of the student, id\_subject is the assignment identifier for which the student registers time,  \em activity\_date\_checkin \em  is the timestamp in which the student recorded the learning activity in milliseconds (e.g. “1431164340000” is the “17/09/2014 at 5:39 AM)”,  \em activity\_date\_checkout \em  is the timestamp in which the student finished the learning activity in milliseconds,  \em activity\_date\_latitude \em  and \em activity\_date\_longitude \em are the coordinates in decimal degrees where the student registered the activity (e.g. somewhere studying by train in the City of Calatayud would be “41.3535300” and “-1.6431800” respectively,  \em activity\_record\_mode \em indicates whether the student is recording the activity using the synchronous option from LearnTracker client, i.e. value “0” means that the student clicked on the start button when started the activity (see play in figure \ref{fig:sload_3b}) and afterwards clicked the end button when he finished the learning activity (see stop in figure \ref{fig:sload_3c}). The asynchronous option represented by the value “1”, means that after finishing the learning activity, the student records the duration of the activity (figure \ref{fig:sload_3b}, selecting the time in the slider and using fast forward button). This table is used for reading when the LeanTracker client loads the data from the backend as well as for writing for each activity recorded.
\end{itemize}
\begin{figure}
     \centering
     \includegraphics[width=0.7\linewidth]{img/studyload_fig2}
     \caption{LearnTracker's Backend database model}
     \label{fig:sload_2}
\end{figure}

\textbf{Webservices}. The LearnTracker Backend features a set of RESTful web services with the aim to provide access to the database from any device connected via HTTP to the Internet. An API has been implemented and released to facilitate the development of further new clients (i.e. iOS, Windows, Blackberry, browser version). The API\footnote{LearnTrackers Backend RESTful API: https://apis-explorer.appspot.com/apis-explorer/?base=https://lifelong-learning-hub.appspot.com/\_ah/api\#p/}  and its commands are described in Appendix AAAAAAAAAFIXTHIS.

\subsubsection{Mobile clients}
\textbf{LearnTracker for Android}. The LearnTracker client is an adaptation from the NFC-LearnTracker\footnote{NFC LearnTracker. Video description: https://www.youtube.com/watch?v=Rl-jAII4IN8}  \citep{Tabuenca2014f,TabuencaLT2014b}, a standalone application developed for NFC-enabled devices released\footnote{NFC LearnTracker. APP in Google Play: https://play.google.com/store/apps/details?id=org.ounl.lifelonglearninghub} in March 2014 . The LearnTracker has been designed on the seamless notion that lifelong learners can study in a variety of scenarios switching from one scenario or context to another easily and quickly, using the personal device as a mediator. Students can use their personal mobile device to record their study-time across context. Based on these time logs, suitable visualizations with learning analytics can be served with to provide feedback on the time devoted to each learning activity. The LearnTracker contrasts the NFC-LearnTracker in the following features:
\begin{itemize}
\item Learning goal definition. Teacher created goals vs. learner created goals. Learn-Tracker provides mobile support for students enrolled in online courses in which the learning goals are predefined by teachers or instructional designers. Most of the times, courses are planned clustering the content in activities, estimating when the activity should be started and the quantity of time that should be devoted to accomplish the learning goal. Teachers define learning goals in LearnTracker (figure \ref{fig:sload_3a}) based on the yardstick of the subject, in contrast to NFC-LearnTracker in which the learner defines his personal learning goals based on own motivations and circumstances.
\item Data storage. Remotely stored data vs. locally stored data. Courses deployed in LearnTracker are retrieved from the remote database at LearnTracker Backend. Likewise, time-logs are also recorded in the backend. Nonetheless, NFC-LearnTacker is a standalone app displaying learning goals that are previously created by the student in a client database. Time-logs are recorded in local client data-base in the mobile devices. This feature implies remarkable differences in two aspects: 1) Connectivity. LearnTracker requires Internet connection to store the data whereas NFC-LearnTracker does not. 2) Privacy. Time-logs in LearnTracker are recorded in a public remote database in contrast to NFC-LearnTracker in which the data is stored in private mobile device.
\item  Interaction. Friction vs. frictionless interactions. At the present time, tagged objects are widely accepted and the prominent adoption of Near Field Communication from the main mobile vendors in the last months (i.e. Apple from iOS 8 or Samsung from Android Kit Kat) has boosted this technology from an innovator to an early adopter phase. Mobile NFC technology has been increasing implemented in different learning contexts in the last years \citep{Tabuenca2014b}. Nevertheless, (as to date March 2015) the majority of the students do not own an NFC-enabled mobile phone. Students using NFC-LearnTracker tap on NFC-tags (i.e. attached to books, etc.) to record when they start and stop studying on a specific activity. Students using LearnTracker click play every time they start studying an activity (figure \ref{fig:sload_3b}), and tap stop when they finish working on the activity (figure \ref{fig:sload_3c}).
\item  Learning analytics type. Personal vs. social. Learning analytics are measures reporting on data about the students and their context for purposes of understanding learning and the environments in which it occurs. NFC-LearnTracker features learning analytics monitoring patterns and the behaviour of the student (i.e. figure \ref{fig:sload_4a}). LearnTracker additionally provides social learning analytics contrasting the time devoted by the student with the time devoted by his colleagues at the classroom (figure \ref{fig:sload_4b}, \ref{fig:sload_4c}), as well as the time initially estimated by the teacher (figure \ref{fig:sload_4c}).
\end{itemize}

\begin{center}
\begin{figure}[ht]
\centering
	\subfloat[Yardstick comprising activities scheduled in the GIS course]{
		\includegraphics[width=0.3\linewidth]{img/studyload_fig3a}
		\label{fig:sload_3a}
	}
	\subfloat[Check-in: Tap to start learning activity ''2.1 Abstraction and perception'']{
		\includegraphics[width=0.3\linewidth]{img/studyload_fig3b}
		\label{fig:sload_3b}
	}	
	\subfloat[Check-out: Tap to stop learning activity  ''2.1 Abstraction and perception'']{
		\includegraphics[width=0.3\linewidth]{img/studyload_fig3c}
		\label{fig:sload_3c}
	}	
      \caption{LearnTracker client for Android}
      \label{fig:sload_3}
\end{figure}
\end{center}

\begin{center}
\begin{figure}[ht]
\centering
	\subfloat[PieChart. Time devoted by a student on the activities in a course]{
		\includegraphics[width=0.3\linewidth]{img/studyload_fig4a}
		\label{fig:sload_4a}
	}
	\subfloat[Linechart. X-axis illustrates activities in a course. Y-axis represents the number of hours devoted to study. My time (violet line) vs. My colleagues’ time (black line)]{
		\includegraphics[width=0.3\linewidth]{img/studyload_fig4b}
		\label{fig:sload_4b}
	}	
	\subfloat[Linechart. X-axis illustrates activities in a course. Y-axis represents number of hours devoted to study. My time (violet line) vs. My colleagues’ time (red line) vs. My teacher’ estimation (blue line)]{
		\includegraphics[width=0.3\linewidth]{img/studyload_fig4c}
		\label{fig:sload_4c}
	}	
      \caption{Learning analytics in LearnTracker}
      \label{fig:sload_4}
\end{figure}
\end{center}

\textbf{Multiplatform web interface}. The multiplatform web interface was designed with the aim to enrol those students that did not own an android device in the experiment. A mobile adapted online form was created based on the yardstick of the course so students can log their time via mobile web browser (figure \ref{fig:sload_5a}). The results spreadsheet was extended to present visualizations summarizing the recordings every time they recorded time: a pie chart showed the overall percentage of distribution of time by assignment (figure \ref{fig:sload_5b}); a barchart showed the time the had devoted to each assignment in contrast to the time initially estimated by the teacher (figure \ref{fig:sload_5c}). 
\begin{center}
\begin{figure}[ht]
\centering
	\subfloat[Yardstick]{
		\includegraphics[width=0.3\linewidth]{img/studyload_fig5a}
		\label{fig:sload_5a}
	}
	\subfloat[Piechart. Time devoted to each learning activity]{
		\includegraphics[width=0.3\linewidth]{img/studyload_fig5b}
		\label{fig:sload_5b}
	}	
	\subfloat[Barchart. My time VS time initially scheduled by the teacher]{
		\includegraphics[width=0.3\linewidth]{img/studyload_fig5c}
		\label{fig:sload_5c}
	}	
      \caption{Multiplatform web interface}
      \label{fig:sload_5}
\end{figure}
\end{center}
\subsubsection{Notifications and SMS broadcasting tool}
The notifications broadcasted to students were designed based on lessons learned and conclusions taken from previous research \citep{Tabuenca2014,TabuencaCAA2014}. Hence, the list of notifications offered to the students in this experiment (see list in Appendix XXXXXXXXXXXXXXXXXXXXX) aimed at covering the following four key requirements:
\begin{itemize}
\item Notifications should be customized and non-repetitive. \cite{Tabuenca2014} offered SMSs with repeated and structured introspective episodes meant to make learning visible. The authors propose further research prompting customized and non-repetitive notifications rather than regular notifications with similar content to keep attracting the attention of the user during the course. Herby, the notifications designed in this experiment included their name to capture their attention as well as useful non-repetitive content (tips \& analytics), and finally the link to their personal logging tool.
\item Notifications should trigger something and clearly prompt the action to do. The notifications designed in this experiment offered explicit signals to students on what to do next towards better time management and self-regulation (see Appendix BBBBBBBBBB. i.e. plan ahead; focus; record your time.).
\item Notifications should stimulate curiosity. The notifications designed in this experiment aimed at attracting users to learn more on time management offering riddles to students so they could stop and reflect what they might find if they would do so (i.e. “Sunday is the day of the week in which your colleagues reported more study-time”; “Your colleagues are reporting an average of 4 hours 20 minutes of study-time per week”). 
\item Notifications should be well timed to produce an instantaneous emotional effect on what to do next. Nowadays, smartphone users are constantly receiving notifications from applications that provide feedback, reminders, recommendations or announcements, hence it is important to offer suitable notifications (in time, in number of instances and the frequency) so the emotional effect keeps active along the course. Previous studies offering notifications in-action (during the course) and on-action (after the study session) highlight the importance of offering notifications in a suitable moment so students are not overwhelmed and loose the interest on the signals \citep{Tabuenca2014}. In this study two notifications per week were broadcasted aiming the following three purposes: a) plan ahead your learning day, thus a set of notifications were scheduled early in the morning; b) summarize and reflect how was your learning day, thus a set of notifications were scheduled late in the evening; c) sampling of experiences in context, thus a set of notifications were scheduled randomly during day-time.
\end{itemize}
Based on these four requirements, an online SMS-broadcasting platform\footnote{SMS online broadcasting tool. Textmagic. https://www.textmagic.com} was selected. Notifications were customized uploading the data from the students (name, phone number, mobile tool). Afterwards, a template was created for every notification so the customized data was inserted within the tags (See Appendixsssssssssssssssssssssss: \{First name\}\{URL mobile tool\}). Finally, the notifications were scheduled and launched based on the previously defined time patterns (figure \ref{fig:sload_6}).

\begin{center}
\begin{figure}[ht]
\centering
	\subfloat[SMS management tool]{
		\includegraphics[height=0.4\linewidth]{img/studyload_fig6a}
		\label{fig:sload_6a}
	}
	\subfloat[SMSs generated out of the templates]{
		\includegraphics[height=0.4\linewidth]{img/studyload_fig6b}
		\label{fig:sload_6b}
	}		
      \caption{SMS broadcasting tool}
      \label{fig:sload_6}
\end{figure}
\end{center}
\subsection{Design of the experiment}
As illustrated in figure \ref{fig:sload_7}, the design of this experiment consisted in four repeated measures of the dependent variables “validity and reliability of time management” and “self-regulation” in which all the students had the same treatment. The treatment was varied after every measure based on the independent variables of “timing” (scheduled and randomized) and “content” (generic tips, learning analytics) of the notifications. Additionally, measures of usability and perceived usefulness of the implementation were taken during the course.

\begin{figure}
     \centering
     \includegraphics[width=0.9\linewidth]{img/studyload_fig7}
     \caption{Experimental design}
     \label{fig:sload_7}
\end{figure}
\subsection{Measure instruments}
\subsubsection{Self-regulation}
Previous research has indicated that self-reported measures of self-regulation have been unreliable as over-estimates of self-regulated learning \citep{Jamieson-Noel2002}. The Online Self-Regulated Learning Questionnaire (OSLQ) has been evaluated with an acceptable measure of self-regulation in the online and blended learning environments \citep{Barnard2009}. The OSLQ consists of six subscale constructs including “environment structuring”, “goal setting”, “time management”, “help seeking”, “task strategies”, and “self-evaluation”. The OSLQ is an adaptation of the Motivated Strategies for Learning Questionnaire \citep{Pintrich2000,Cheng2013} to evaluate self-regulation in online learning environments. The OSLQ is a 24-item scale with a 5-point Likert-type response format having values ranging from strongly agree (5) to strongly disagree (1). 

\subsubsection{Validity and reliability of time management}
The aim of this research is investigating on the whether the intervention proposed would produce positive effects in self-regulation with a special focus on how learners manage their time. Hence, the Validity and Reliability of Time Management Questionnaire (VRTMQ) \citep{Alay2002} was included in the measures. The VRTMQ consists of 3 subscale constructs, including “time planning”. “time attitudes” and “time wasters”. The VRTMQ is 27-item scale with a 5-point Likert-type response format having values: 1) always; 2) frequently; 3) sometimes; 4) infrequently; 5) never.

\subsubsection{Time patterns}
The time-logs recorded with the mobile clients described before are used to analyse and understand patterns on how students learn along the day, along the week and during the whole course.

\subsubsection{Complexity of the mobile tool}
Three indicators are taken to contrast the complexity of the tool:

Usability and learnability. The System Usability Scale (SUS) \citep{Brooke1996} was used to evaluate both mobile tools. The SUS scale consists of ten questions with a five-point Likert scale clustered in learnability and usability subscales. Based on the current literature, a SUS score above 68 (SD: 12.5) is rated as above average usability score. The analysis of the results has followed the recommendations from Sauro \citep{Sauro2011} so they can be mapped and benchmarked against 446 previous studies and 5000 individual responses. 

Interaction. Recent work suggests a set of interaction guidelines in designing mobile learning tools to achieve efficiency, effectiveness and satisfaction of learning \citep{Seong2006}. The authors stress the importance in the number of click, scrolls or swipes to navigate within the app, as well as the quantity of information contained per page “ \em Extensive scrolling and the number of clicks should be well thought. The height and width of the display area should not exceed the screen size. Long pages should be segmented into smaller chunk and provide effective mechanism to view and jump to the desired page whenever users initiate an action or click on it \em ”. Hence, the researchers have explored both mobile tools with the aim to identify shortcomings and report lessons learned regarding the interaction with the mobile tools. 

\subsection{Procedure}
The authors contacted online instructors via email asking for participation in an experiment that aimed at fostering self-regulation of students with technology. Three instructors accepted the invitation and granted permission for the researchers to advertise the experiment and provide instruction in the online platform. Afterwards, the researchers collected the information about the yardsticks of the courses from the teachers (activities, start dates and estimated durations). This data was deployed in the database hosted in the backend making it available to the mobile clients.

The day of the kick-off, the experiment was presented to the students to estimate how accurate estimations by instructional designers are with regard to the time needed to accomplish each learning activity scheduled in a course. Hence, the researchers warn students of the importance of making truthful time-logs stressing the correlation between the accuracy of their time-logs and the quality of the feedback the students would retrieve in the learning analytics. The teachers clarified that the number of time-logs recorded would not affect their grades and participants were assured that their responses would remain anonymous and confidential. Both mobile tools were demoed and students were invited to voluntarily select the one they might find handier based on their preferences and their mobile features. 

Concurring with the course kick-off, the mobile tools used in this experiment were presented in a technology enhanced learning workshop  that gathered teachers and researchers with the aim find suitable combinations between theory and practice. The feedback collected in this meeting was useful to identify potential uses of the information collected with these tools and which chart visualizations matches better to each scenario. These conclusions are further analysed in the discussion section of this manuscript.

Questionnaires data were imported from the Web into MS Excel format and then imported into R Studio (v 0.98.1102). Time-logs data were exported from the backend to JSON format, converted to comma-separated-files and imported into MySQL tables. Based on the proposed research questions, some SQL queries were created and the results exported to be finally imported and analysed into MS Excel or R Studio (v 0.98.1102).

\subsection{Data analysis}
\section{Results}
\subsection{Impact of logging/monitoring time in self-regulation}
The data obtained in the course C1 is used to evaluate the first hypothesis (H1). The scores obtained from OSLQ demonstrated adequate internal consistency of scores with $\alpha$ = .80. \cite{Nunnally1994} has suggested that score reliability of .70 or better is acceptable. When examining the internal consistency of scores by subscale (Table 1), values for Cronbach alpha ranged from .76 to .83 revealing sufficient score reliability for “goal setting”, “environment structuring” and “time management”. Nevertheless, values for Cronbach alpha ranged from .41 to .50 revealing insufficient score reliability for “self-evaluation” and “task strategies”. “Help seeking” was accounted as reliable due to its close approximation to the acceptance value.
The scores obtained from the VRTMQ demonstrated adequate internal consistency of scores with ? = .89. When examining the internal consistency of scores by subscale, values for Cronbach alpha were .92 revealing sufficient score reliability for “time planning”. Nevertheless, values for Cronbach alpha ranged from .30 to .56 revealing insufficient score reliability for “Time attitudes” and “Time wasters”.

\begin{table}[h]
  \centering
  \small
  \caption{Internal consistency of OSLQ and VRTMQ (n=52). * Cronbach's alpha >=70}
  \label{tbl:studyload_table1}

\begin{tabular}{llcr}
\hline
\textbf{Scale} & \textbf{Subscale}                        & \textbf{Num. items} & \textbf{$\alpha$}                 \\
\hline
OSLQ           & Goal setting                             & 5                   & .83*                              \\
               & Environment structuring                  & 4                   & .78*                              \\
               & Time management                          & 3                   & .76*                              \\
               & Help seeking                             & 4                   & .69*                              \\
               & Self-evaluation                          & 4                   & .50                               \\
               & Task strategies                          & 4                   & .41                               \\
\textbf{}      & \multicolumn{1}{r}{\textbf{Total scale}} & \textbf{24}         & \textbf{.80*}                     \\
\hline
VTMQ           & Time planning                            & 16                  & .92*                              \\
               & Time attitudes                           & 7                   & .56                               \\
               & Time wasters                             & 4                   & .30                               \\
\textbf{}      & \multicolumn{1}{r}{\textbf{Total scale}} & \textbf{27}         & \multicolumn{1}{l}{\textbf{.89*}}\\ \hline
\end{tabular}
\end{table}

A Shapiro–Wilk test was conducted with the aim to confirm the normal distribution assumption towards performing an analysis of variance (ANOVA). The p-values lower than 0.05 and the observations of the Q-Q plots conclude that the samples (goal setting, environment structuring, time management and time planning) deviate from normality. Alternatively to ANOVA, a Friedman’s ANOVA test was performed. This test is used for testing differences between conditions when there are more than two conditions, the same participants have been used in all conditions, and the samples are non-normally distributed. 

\begin{table}[h]
  \centering
  \small
  \caption{Means for the course C1. 5) Strongly disagree; 4) Disagree; 3) Neutral; 2) Agree; 1) Strongly agree; (*Friedman’s ANOVA significance: p < .05)}
  \label{tbl:studyload_table2}
\begin{tabular}{llllllc}
\hline
\textbf{}      & \textbf{}               & \multicolumn{4}{c}{\textbf{Measures}}                                                                                                         &\multicolumn{1}{c}{\textbf{ANOVA}}  \\
\textbf{Scale} & \textbf{Subscale}        & \multicolumn{1}{c}{\textbf{M0}} & \multicolumn{1}{c}{\textbf{M1}} & \multicolumn{1}{c}{\textbf{M3}} & \multicolumn{1}{c}{\textbf{M3}} & \textbf{p-value}          \\
\hline
OSLQ           &                         & 2.67                            & 2.56                            & 2.44                            & 2.55                            & .46                       \\
               & Goal setting            & 2.46                            & 2.00                            & 2.03                            & 2.00                            & .20                       \\
               & Environment structuring & 1.87                            & 1.88                            & 1.62                            & 1.85                            & .36                       \\
               & Time management         & 2.92                            & 2.23                            & 2.15                            & 2.21                            & .06                       \\
               & Help seeking            & 2.92                            & 3.05                            & 2.92                            & 3.07                            & .67                       \\
\hline               
VRTMQ          &                         & 2.82                            & 2.68                            & 2.69                            & 2.55                            & .07                       \\
               & Time planning           & 2.72                            & 2.41                            & 2.38                            & 2.25                            & .12                       \\
\hline            
\end{tabular}
\end{table}

The results concluded in non-significant variances in the means justified by the low rate of participation in all the four measures (n=13). Hence, subscales with significance value lower or close to 0.1 were further examined. Based on this assumption, these results determine that the experimental manipulation has had some effect in “time management” and “time planning” subscales. This implies that one or more of the differences between mean is statistically significant. It is, therefore, necessary to carry out further analysis to find out which measure differ. As our specific hypothesis is that there will increasing rates of “time management” (TM) and “time planning” (TP) as the experiment progresses, a set of planned contrast analysis were performed to determine whether our assumptions are true for the following sub-hypothesis:
\begin{itemize}
\item Hypothesis 1a: The first measure (M0) of the dependent variables “time management” and “time planning” is significantly lower than the subsequent measures.
\item Hypothesis 1b: The first intermediate measure (M1) of the dependent variables is significantly lower than the subsequent measures.
\item Hypothesis 1c: The second intermediate measure (M2) of the dependent variables is significantly lower than the last measure.
\end{itemize}

\begin{table}[h]
  \centering
  \small
  \caption{Planned contrast for time management and time planning subscales. * Significance: p < .05}
  \label{tbl:studyload_table3}
  
\begin{tabular}{rcccccc}
\thickhline
\multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Planned\\ contrast\end{tabular}}} & \multicolumn{2}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Contrast 1\\ Hypothesis 1a\end{tabular}}}                          & \multicolumn{2}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Contrast 2\\ Hypothesis 1b\end{tabular}}}                       & \multicolumn{2}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Contrast 3\\ Hypothesis 1c\end{tabular}}}                       \\ \hline
\thickhline
Measure                                                                                & TM                                                          & TP                                                         & TM                                                        & TP                                                        & TM                                                       & TP                                                         \\ \hline
M0                                                                                      & X                                                           & X                                                          & -                                                         & -                                                         & -                                                        & -                                                          \\ \hline
M1                                                                                      & \begin{tabular}[c]{@{}c@{}}(t=-2.14,\\ p=.03)*\end{tabular} & \begin{tabular}[c]{@{}c@{}}(t=-1.23,\\ p=.22)\end{tabular} & X                                                         & X                                                         & -                                                        & -                                                          \\ \hline
M2                                                                                      & \begin{tabular}[c]{@{}c@{}}(t=-2.37,\\ p=.02)*\end{tabular} & \begin{tabular}[c]{@{}c@{}}(t=-1.34,\\ p=.18)\end{tabular} & \begin{tabular}[c]{@{}c@{}}(t=-.20,\\ p=.81)\end{tabular} & \begin{tabular}[c]{@{}c@{}}(t=-.10,\\ p=.91)\end{tabular} & X                                                        & X                                                          \\ \hline
M3                                                                                      & \begin{tabular}[c]{@{}c@{}}(t=-2.22,\\ p=.03)*\end{tabular} & \begin{tabular}[c]{@{}c@{}}(t=-1.83,\\ p=.07)\end{tabular} & \begin{tabular}[c]{@{}c@{}}(t=-.08,\\ p=.93)\end{tabular} & \begin{tabular}[c]{@{}c@{}}(t=-.50,\\ p=.56)\end{tabular} & \begin{tabular}[c]{@{}c@{}}(t=.15,\\ p=.88)\end{tabular} & \begin{tabular}[c]{@{}c@{}}(t=-.50,\\ p=.61)\end{tabular} \\ \thickhline
\end{tabular}
\end{table}

The results of the first contrast determine that all measures taken during the course concluded in significant improvements in TM with respect to the initial measure at the kick-off of the course. Regarding the measure of TP, there was no significant variances and there might be only an improvement from the initial measure to the last one (p=.07). The results of the second and third contrast do not conclude significant variance between the intermediate measures of TM nor TP during the course. Overall these results substantiate the trends illustrated by the means in figure \ref{fig:sload_8a}. TM means in figure 8a) depict an increase in this skill from the first measure (M0) to the second one (M1). This positive effect is again notable from the third measure (M2) to the next one (M1). The last measure concluded with similar values to its preceding. Means in figure \ref{fig:sload_8b} depict an increase in TP from the second measure (M2) to the first one (M0). Later on, this measure reports similar values peaking slightly down in the second intermediate measure (M2).

\begin{center}
\begin{figure}[ht]
\centering
	\subfloat[Time management]{
		\includegraphics[width=0.4\linewidth]{img/studyload_fig8a}
		\label{fig:sload_8a}
	}
	\subfloat[Time planning]{
		\includegraphics[width=0.4\linewidth]{img/studyload_fig8b}
		\label{fig:sload_8b}
	}	

      \caption{Boxplot with mean scores for significant subscales. 5) Strongly disagree; 4) Disagree; 3) Neutral; 2) Agree; 1) Strongly agree;}
      \label{fig:sload_8}
\end{figure}
\end{center}

\subsection{Impact of timing the notifications in self-regulated learning}
The data obtained in the course C1 is used to evaluate this research question. Measures M0, M2 and M3 (n=39) are taken to contrast differences in TP and TM when varying the independent variable “timing” with scheduled-based notifications and random-based notifications. As our specific hypothesis is that students will improve “time management” (TM) and “time planning” (TP) skills when they receive notifications in schedule basis rather than when they receive notifications in random basis, a set of planned contrast is performed to determine whether our assumptions are true for the following hypothesis:
\begin{itemize}
\item Hypothesis 2: The intermediate measure M2 is significantly higher than the final measure M3, in contrast to the initial measure in M0.
\end{itemize}

\begin{table}[h]
  \centering
  \small
  \caption{Planned contrast for time management and time planning subscales. * Significance: p < .05}
  \label{tbl:studyload_table4}
  
\begin{tabular}{rcccc}
\thickhline
\multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Planned\\ contrast\end{tabular}}} & \multicolumn{2}{c}{\textbf{Contrast 1}} & \multicolumn{2}{c}{\textbf{Contrast 2}} \\ \thickhline
Measure                                                                                & TM                  & TP                & TM                  & TP                \\ \hline
M0                                                                                      & X                   & X                 & -                   & -                 \\ \hline
M2                                                                                      & (t=-2.52, p=.01)*   & (t=-1.47, p=.15)  & X                   & X                 \\ \hline
M3                                                                                      & -                   & -                 & (t=-2.52, p=.07)    & (t=-.10, p=.91)   \\ \thickhline

\end{tabular}
\end{table}

The differences in the contrasts confirm significant differences in the variances from the initial measure M0 to M2 in TM (p=.01). Nevertheless, the variances in TM and TP are not significant in M3 in contrast to M0 (p=.07 in both TM and TP). Figure \ref{fig:sload_9} show that the differences in the mean contrasts to the initial measure M0 are slightly higher in M2 (.77) than in M3 (.72), and consequently confirming our hypothesis.

\begin{center}
\begin{figure}[ht]
\centering
	\subfloat[Contrast 1. Notifications pushed at fixed time of the day]{
		\includegraphics[width=0.4\linewidth]{img/studyload_fig9a}
		\label{fig:sload_9a}
	}
	\subfloat[Contrast 2. Notifications pushed on random basis in the time of the day]{
		\includegraphics[width=0.4\linewidth]{img/studyload_fig9b}
		\label{fig:sload_9b}
	}	
      \caption{Boxplots with measure of means in “time management” subscale. 5) Strongly disagree; 4) Disagree; 3) Neutral; 2) Agree; 1) Strongly agree;}
      \label{fig:sload_9}
\end{figure}
\end{center}

\subsubsection{Patterns sampling study time}
\textbf{Distribution of time-logs along the day}. Time-logs registered during the courses C1, C2 and C3 are analysed to evaluate this research question. Students were able to log their study-time at any moment of the day along the week. As our specific hypothesis (H4) is the existence of patterns describing the way in which students study and log their time, our assumptions are true whenever we are able to find and understand these patterns.

Based on the results illustrated in figure \ref{fig:sload_10}, there are three levels of intensity in the activity with regard to the number of time-logs performed:
\begin{itemize}
\item High Intensity (HI >80): Time ranges between 9h to 15h and 18h to 22h.
\item Medium Intensity (20 < MI > 80): Time ranges between 8h to 9h, 15h to 18h and 22h to 0h.
\item Low Intensity (LI < 20): Time ranges between 0h and 8h.
\end{itemize}
Regarding the average duration in the time-logs, students reported to study in longer time slots at 20h (100 minutes), 12h and 22h (80 minutes).

\begin{figure}
     \centering
     \includegraphics[width=0.9\linewidth]{img/studyload_fig10}
     \caption{Distribution of time logs along the day (n=1217). Y-axis represents the number of time-logs during the day. X-axis represents the time of the day. The width of the plot represents the mean duration of the time-logs for an hour.}
     \label{fig:sload_10}
\end{figure}

Herby we explore how variations in timing of the notification moderate the number and the duration of the time-logs. Time-logs registered during the courses C1 are analyzed to evaluate this research question (time-logs C2 and C3 are not included in this analysis for not being comparable to C1). As our specific hypothesis is that notifications will foster participants towards studying and consequently recording their time in the moment they receive the notification, our assumptions are true whenever there is a correlation between the timestamp when the notifications are triggered and the number (and duration) of time-logs recorded immediately after the notification. Figure \ref{fig:sload_11} illustrates the time-logs recorded for the weeks in which the notifications were broadcasted at 20h. Figure \ref{fig:sload_12} illustrates the time-logs recorded for the weeks in which the notifications were broadcasted at 10h. Figure \ref{fig:sload_13} illustrates the time-logs recorded for the weeks in which the notifications were broadcasted at scattered moments in the day.

\begin{figure}
     \centering
     \includegraphics[width=0.8\linewidth]{img/studyload_fig11}
     \caption{Y-axis is the number of logs. X-axis is the time of the day. Relationship between the SMS notifications and students’ time-log reactions. Submitting message in the evening at 20h (vertical red dashed line). The thickness of the plot indicates the duration of the time-logs recorded}
     \label{fig:sload_11}
\end{figure}

\begin{figure}
     \entering
     \includegraphics[width=0.8\linewidth]{img/studyload_fig12}
     \caption{Y-axis is the number of logs. X-axis is the time of the day. Relationship between the SMS notifications and students’ time-logs reaction. Submitting message in the morning at 10h (vertical red dashed line). The thickness of the plot indicates the duration of the time-logs recorded.}
     \label{fig:sload_12}
\end{figure}

\begin{figure}
     \centering
     \includegraphics[width=0.8\linewidth]{img/studyload_fig13}
     \caption{Y-axis is the number of logs. X-axis is the time of the day. Relationship between the SMS notifications and students’ time-logs reaction. Submitting message on random basis (vertical red dashed line). The thickness of the plot indicates the duration of the time-logs recorded.}
     \label{fig:sload_13}
\end{figure}

\textbf{Preferred timing}. The last measure (M3) of the course C1 (n=13) included a question so students could rate from 1 to 5 their preference with regard to the timing when the notifications were delivered. Table \ref{tbl:studyload_table6} presents the results reported to the question: “ \em You are receiving SMSs in three different time patterns. Rate your preference to receive these notifications. \em ”
\begin{table}[h]
  \centering
  \small
  \caption{Preferred timing. 5-Likert scale: 5.Most preferred; 3.Neutral; 1.Least preferred}
  \label{tbl:studyload_table6}
\begin{tabular}{ccc}
\hline
\textbf{10h M(SD)} & \textbf{20h M(SD)} & \textbf{Random M(SD)} \\ \hline
3.77(.83)          & 2.92(1.04)         & 2.85(.52)             \\ \hline
\end{tabular}
\end{table}

\textbf{Distribution of time-logs along the week}. As illustrated in table \ref{tbl:studyload_table5}, average time-logs per day fluctuate between 58 minutes to 83 minutes along the week. Students reported more minutes and more time-logs on Thursdays and Sunday. Longer time-logs were reported on Tuesdays and Wednesdays whereas the shorter ones are reported Mondays and Fridays. 
\begin{table}[h]
  \centering
  \small
  \caption{Distribution of time-logs along the week}
  \label{tbl:studyload_table5}
  
\begin{tabular}{rrrc}
\hline
\textbf{Week day} & \textbf{Time-logs(n)} & \textbf{Minutes-logged(n)} & \textbf{\begin{tabular}[c]{@{}c@{}}Mean duration of\\ time-logs in minutes\end{tabular}} \\
\hline
Monday            & 12.00\% (n=146)       & 10.56\% (n=8499)           & 58.21                                                                                    \\
Tuesday           & 12.16\% (n=148)       & 15.39\% (n=12387)          & 83.69                                                                                    \\
Wednesday         & 12.90\% (n=157)       & 14.80\% (n=11913)          & 75.87                                                                                    \\
Thursday          & 20.95\% (n=255)       & 18.56\% (n=14937)          & 58.57                                                                                    \\
Friday            & 11.34\% (n=138)       & 10.69\% (n=8603)           & 62.34                                                                                    \\
Saturday          & 12.08\% (n=147)       & 11.75\% (n=9457)           & 64.33                                                                                    \\
Sunday            & 18.57\% (n=226)       & 18.25\% (n=14692)          & 65.00                                                                                   \\
\hline
\end{tabular}
\end{table}

\subsubsection{How do students log their time}
Students using the LearnTracker app were able to decide between recording their time in-action (figures \ref{fig:sload_3b} \ref{fig:sload_3c}: clicking play when they start studying and clicking stop when they finish) or on-action (figure \ref{fig:sload_3b}: clicking fast-forward when finished studying). Students using the Multiplatform web-interface could only record time their on-action. The records from the LearnTracker app are taken as indicator to identify preferences in the way to record time. 58.43\% (n=534) of the recordings were performed synchronously in-action whereas the 41.57\% (n=380) record their time asynchronously on-action.

\subsubsection{Correlation between time-logs and performance}
The data obtained in the course C1 is used to evaluate this research question. Time-logs recorded during the course (n=1030) and the grades obtained in the final evaluation are taken as indicator. A Pearson’s correlation analysis was performed with the aim to measure the strength in the relation between the grades obtained by the students and their time-logs along the course. The correlation of analysis between the grades and the number of time logs concluded in .37 (p=.20), whereas the correlation analysis between the grades and the total time recorded concluded in .09 (p=.76). 

\subsection{Impact from the content of the notifications in self-regulation}
Herby we explore how variations in the content of the notification moderate the number and the duration of the time-logs. The data obtained in the course C1 is used to evaluate this research question. Measures M0, M1 and M2 (n=39) are taken to contrast differences in TP and TM when varying the independent variable “content” with generic tips for self regulation and learning analytics. As our specific hypothesis is that students will improve “time management” (TM) and “time planning” (TP) skills when they receive learning analytics rather than tips, a set of planned contrast is performed to determine whether our assumptions are true for the following hypothesis:
\begin{itemize}
\item Hypothesis 3: The intermediate measure M2 has higher significance in contrast to the initial measure M0, than the intermediate measure M1 in contrast to the initial measure in M0.
\end{itemize}

\begin{table}[h]
  \centering
  \small
  \caption{Planned contrast for time management and time planning subscales. * Significance: p < .05}
  \label{tbl:studyload_table7}
  
\begin{tabular}{rcccc}
\thickhline
\multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Planned\\ contrast\end{tabular}}} & \multicolumn{2}{c}{\textbf{Contrast 1}} & \multicolumn{2}{c}{\textbf{Contrast 2}} \\ \thickhline
Measure                                                                                & TM                  & TP                & TM                  & TP                \\ \hline
M0                                                                                      & X                   & X                 & -                   & -                 \\ \hline
M1                                                                                      & (t=-2.14, p=.04)*   & (t=-1.19, p=.24)  & X                   & X                 \\ \hline
M2                                                                                      & -                   & -                 & (t=-2.52, p=.01)*   & (t=-.47, p=.15)   \\ \thickhline
\end{tabular}
\end{table}

The differences in the contrasts for TM confirm significant variances in M2 (p=.01) and M1 (p=.04). The differences in the contrasts do not confirm significant variances for TP. Figure \ref{fig:sload_14} shows that the differences in the mean contrasts to the initial measure M0 are slightly higher in M2 (.77) than in M1 (.70), and consequently confirming our hypothesis.

\begin{center}
\begin{figure}[ht]
\centering
	\subfloat[Contrast 1. Notifications containing generic tips]{
		\includegraphics[width=0.4\linewidth]{img/studyload_fig14a}
		\label{fig:sload_14a}
	}
	\subfloat[Contrast 2. Notifications containing learning analytics]{
		\includegraphics[width=0.4\linewidth]{img/studyload_fig14b}
		\label{fig:sload_14b}
	}		
      \caption{Boxplots with measure of means in “time management” subscale. 5) Strongly disagree; 4) Disagree; 3) Neutral; 2) Agree; 1) Strongly agree;}
      \label{fig:sload_14}
\end{figure}
\end{center}

\subsubsection{Preference in content and channels}
The second intermediate measure (M2) of the course C1 included a question so students could rate their preference with regard to the content of the notifications. Table \ref{tbl:studyload_table8} presents the results reported to the question: “ \em You are receiving SMSs in three different time patterns. Rate your preference to receive these notifications. \em ”. As our specific hypothesis is that students will prefer notifications containing learning analytics rather than notifications containing tips for self-regulation, our assumptions are true whenever the rate higher LA than tips. The results presented in Table \ref{tbl:studyload_table8} confirm our hypothesis.

\begin{table}[h]
  \centering
  \small
  \caption{Preferred content. 5-Likert scale: 5.Most preferred; 3.Neutral; 1.Least preferred}
  \label{tbl:studyload_table8}
  
\begin{tabular}{cc}
\hline
\textbf{Learning analytics M(SD)} & \textbf{Tips M(SD)} \\ \hline
2.85(.69)                         & 2.92(1.04)          \\ \hline
\end{tabular}
\end{table}

The last measure (M3) of the course C1 included a question so students could rate their preference with regard to their preferred input channel to receive analytics at their mobile devices. Table \ref{tbl:studyload_table9} presents the results reported to the question: “ \em You are consuming learning analytics from two different channels. Rate your preference with regard to the channel to receive and explore learning analytics. \em ” As our specific hypothesis is that students will prefer pushed SMSs with key interpretations of the analytics rather than pulled visualizations served on demand, our assumptions are true whenever students rate higher preference in SMSs notifications. Contrary to our hypothesis, the results presented in Table \ref{tbl:studyload_table9} show that students preferred learning analytics served in chart visualizations.

\begin{table}[h]
  \centering
  \small
  \caption{Preferred channel. 5-Likert scale: 5.Most preferred; 3.Neutral; 1.Least preferred}
  \label{tbl:studyload_table9}


\begin{tabular}{cc}
\hline
\textbf{SMS notifications M(SD)} & \textbf{Chart visualizations M(SD)} \\ \hline
3.31(.95)                        & 3.46(1.13)                          \\ \hline
\end{tabular}
\end{table}

Additionally, the last measure (M3) of the course C1 included a question so students could rate their preference with regard to the specific content of the learning analytics. Table \ref{tbl:studyload_table10} presents the results reported to the question: “ \em Learning analytics can inform on the time estimated by the teacher, the time you devoted of the time devoted by your colleagues. Rate how useful do you find them. \em ”. As our specific hypothesis is that students will appreciate teacher’s expertise and consequently find their estimations more useful than social or personal learning analytics. Contrary to our hypothesis, the results presented in Table \ref{tbl:studyload_table10} show that students preferred personal learning analytics rather than social or teacher analytics.

\begin{table}[h]
  \centering
  \small
  \caption{Perceived usefulness in Learning Analytics. 5-Likert scale. 5.Most useful; 3.Neutral; 1. Least useful}
  \label{tbl:studyload_table10}
  
\begin{tabular}{ccc}
\hline
\textbf{Personal M(SD)} & \textbf{Social M(SD)} & \textbf{Teacher M(SD)} \\ \hline
3.69(.85)               & 3.46(.88)             & 3.38(.96)              \\ \hline
\end{tabular}
\end{table}

\subsection{Usability of the tool}
The data obtained in the course C1 is used to evaluate this hypothesis 5. Both the LearnTracker and the multiplatform web interface were presented and demoed at the kick-off as mobile tools to record their study-time. Participants were invited to voluntarily use the tool that better fit their preferences and the features of their mobile devices. Table \ref{tbl:studyload_table11} enumerates the list of actions (clicks, swipes or scrolls) needed to log study-time in both tools contrasting the best-case scenario (minimizing the number of interactions selecting first activity in the yardstick, minimizing scrolling selecting HH:MM, etc) with the worst-case scenario (scrolling to select bottom activity in the yardstick, maximum number of HH:MM in the scroll lists). The results show that the LearnTracker for Android requires 4 to 8 eight clicks to log time whereas the Multiplatform web interface requires 8 to 12 clicks.

\begin{table}[h]
  \centering
  \footnotesize
  \caption{Summary of interactions to accomplish a time-log. (* Number of actions / Number of clicks)}
  \label{tbl:studyload_table11}
  
\begin{tabular}{|c|c|c|c|}
\hline
\multicolumn{2}{|c|}{\textbf{LearnTracker for Android}}                                                                                                            & \multicolumn{2}{c|}{\textbf{Multiplatform web interface}}                                                                                                                           \\
\hline
\textbf{Minimum}                                                      & \textbf{Maximum}                                                                           & \textbf{Minimum}                                                                        & \textbf{Maximum}                                                                           \\
                                                                      & \begin{tabular}[c]{@{}c@{}}1 click to \\ start app\end{tabular}                            & \begin{tabular}[c]{@{}c@{}}1 click URL\\ on SMS\end{tabular}                            & \begin{tabular}[c]{@{}c@{}}1 click URL\\ on SMS\end{tabular}                               \\
\begin{tabular}[c]{@{}c@{}}1 click select\\ 1st activity\end{tabular} & \begin{tabular}[c]{@{}c@{}}2 clicks to scroll \\ and select\\ bottom activity\end{tabular} & \begin{tabular}[c]{@{}c@{}}1 click to display \\ HH scroll\\ 1st activity\end{tabular}  & \begin{tabular}[c]{@{}c@{}}2 clicks to scroll \\ and select\\ bottom activity\end{tabular} \\
\begin{tabular}[c]{@{}c@{}}1 click to \\ check-in\end{tabular}        & \begin{tabular}[c]{@{}c@{}}2 scroll bottom \\ HH\end{tabular}                              & \begin{tabular}[c]{@{}c@{}}1 clicks to \\ select HH\end{tabular}                        & \begin{tabular}[c]{@{}c@{}}1 click to \\ display HH scroll\end{tabular}                    \\
\begin{tabular}[c]{@{}c@{}}1 click to \\ check-out\end{tabular}       & \begin{tabular}[c]{@{}c@{}}2 scroll bottom\\ MM\end{tabular}                               & \begin{tabular}[c]{@{}c@{}}1 click on\\ “done”\end{tabular}                             & \begin{tabular}[c]{@{}c@{}}2 clicks to \\ scroll and select\\ bottom HH\end{tabular}       \\
                                                                      & \begin{tabular}[c]{@{}c@{}}1 click fast-fwd \\ asynch. log\end{tabular}                    & \begin{tabular}[c]{@{}c@{}}1 click to display \\ MM scroll \\ 1st activity\end{tabular} & 1 click on “done”                                                                          \\
                                                                      &                                                                                            & \begin{tabular}[c]{@{}c@{}}1 clicks to\\ select MM\end{tabular}                         & \begin{tabular}[c]{@{}c@{}}1 click to display \\ MM scroll\end{tabular}                    \\
                                                                      &                                                                                            & 1 click on “done”                                                                       & \begin{tabular}[c]{@{}c@{}}2 clicks to scroll \\ and select\\ bottom MM\end{tabular}       \\
                                                                      &                                                                                            & 1 click on “send”                                                                       & 1 click on “done”                                                                          \\
                                                                      &                                                                                            &                                                                                         & 1 click on “send”                                                                          \\
\hline                                                                      
\textbf{4/4}                                                          & \textbf{5/8}                                                                               & \textbf{8/8}                                                                            & \textbf{9/12}                                                                             \\
\hline
\end{tabular}
 
\end{table}

After demoing the tools at the kick-off, students become aware of the differences in the complexity of the interactions in number of clicks, as well as of the differences between fast swiping screens within the app, web browser navigation from one page to another. Another relevant difference is that the multiplatform web interface only presents the learning analytics (figures \ref{fig:sload_5b}, \ref{fig:sload_5c}) just after logging time whereas the Learn-Tracker facilitates monitoring of the visualizations at any moment accessing from the yardstick screen (figure \ref{fig:sload_3a}). Hence, some of the non-Android students (i.e. iOS, Windows, Blackberry) expressed to be dissatisfied with the difference in the tooling and did not accept take part in the experiment. These differences were also obvious during the course, when the majority of the Android students completed the whole course logging their study-time in contrast to the multiplatform web interface.

Finally, 11 students decided to use LearnTracker while 6 students selected the mo-bile web interface. The System Usability Scale (SUS) was used for the evaluation of the usability \citep{Brooke1996}. The SUS scale consists of 10 questions with a five-point Likert scale, where item directions are changed in each question. The results of the survey were recorded in an online questionnaire. Based on the current literature, a SUS score above 68 (SD: 12.5) is rated as usability score above average. This analysis have followed the recommendations from \cite{Sauro2011} so that the results can be mapped and benchmarked against 446 previous studies and 5000 individual responses. The evaluation of the usability shows that LearnTracker for Android has a mean score of 76.8 (SD = 8.4), which is remarkably above average. Items 4 and 10 from the questionnaire were taken as subscale for learnability. Average learnability score was 72.7. Items 1, 2, 3, 5, 6, 7, 8, 9 contribute to the construct usability where average score was 93.2. On the other hand, the evaluation of the usability shows that multiplatform web interface has a mean score of 55.0 (SD = 12.6), which is below average. Values for learnability and usability were 95.8 and 44.8 respectively.
\section{Discussion}
\subsection{Interpretation of the results}
This manuscript has explored the use of mobile time-logs to foster self-regulation in online learning environments. Learning analytics delivered to students via mobile chart-visualizations and notifications have been used to support them in the competence development of “learning to learn” \citep{EuropeanCommission2007} by raising awareness on \em time management \em as trigger to foster understanding on meta-learning \citep{Tabuenca2014,Biggs1985}. The analysis of the results concludes in the following findings:
\begin{itemize}
\item H1. Benefits of logging study-time. Findings in this study suggest that using mobile devices to log and track the time devoted to study across contexts has a positive impact on the \em time management \em skills. This subscale of self-regulation \citep{Barnard2009} comprises items assessing whether students allocate extra study-time for online courses, whether students observe the schedule setting aside the same time everyday or every week to study on online courses, and last but not least, whether students even without having the obligation to attend daily classes, still try to distribute study time evenly across days. The results presented in table \ref{tbl:studyload_table3} and illustrated in figure \ref{fig:sload_8a} show increased values in the skill of time management from the first measure to the third one (around 2,5 months treatment), remaining stable in the subsequent measure. Additionally, the results show that there might be a significant positive effect in the measure of time planning (figure \ref{fig:sload_8b}). This subscale \citep{Alay2002} comprises more generic items (beyond online courses) that asses whether students set learning goals, write goals, set priorities, plan ahead the week, etc. These results show that logging and monitoring time can foster time management skills in online courses with increased values from the initial start to the 10th week when the values remain stable. In further research, studies in longer course (than 4 months) should explore whether this measure remains stable or fluctuates after that time.
\item H2. Timing of mobile notifications. Findings in the experiment suggest that notifications pushed at random time of the day do not produce significant improvements in time management. Nevertheless, notifications pushed at fixed times of the day moderate positively the measure of time management. These results are consistent with the answers reported by the students (Table \ref{tbl:studyload_table6}) regarding their timing preference, in which, notifications at 10h were preferred over notifications at 20h as well as over notifications randomized in time. More investigation is needed into the tension of intruding students' “out-of-school” time with notifications. Another reason to argue on these results might be that students prefer notifications that persuade them to (pre-)“plan ahead” their learning day, rather than (post-)“look backward” their learning day or (in-action) “plan” at any moment of the day.
\item H3. Findings in the experiment suggest that notifications containing learning analytics and generic tips on self-regulation influence positively the skill of time management. More specifically, notifications containing learning analytics resulted in slightly higher scores in time management, in comparison to generic tips on self-regulation. These results are also consistent with the answers reported by the students regarding their content preference, in which (see Table \ref{tbl:studyload_table8}), students preferred learning analytics over tips. More specifically, the results presented in Table \ref{tbl:studyload_table10} indicate that students perceive learning analytics informing about their personal time-performance and behaviour more useful, in comparison to learning analytics informing about the progress from peer learners or time per task estimated from the teacher. Table \ref{tbl:studyload_table9} shows that students preferred chart visualizations over text messages to receive learning analytics. Nevertheless, the preference for this channel does not imply that visualizations are more effective. SMS notifications get the primary attention of the students suggesting learning cues in the moment they are pushed to their mobile devices (foreground), whereas chart visualizations are always running in the mobile device and might stay in the background unless there is an intrinsic interest from the students to visualize them and obtain conclusions out of them. 
\end{itemize}
The authors of this research want to further research the effects of SMS to foster self-regulation. Indeed, occasional “stop and think” beacons containing adequately contextualized messages can support students in the competence of learning to learn in online courses, specially when they are combined with suitable visualizations. Taking actions to dismantle barriers (B1.-lack of personalisation; B2.-time and place; B3.- lack of facilities to study at home; B4.-fragmentation in learning experiences;) providing mobile and contextualized learning \citep{Kalz2014} requires finding the suitable balance between prompting mobile learning analytics via chart visualizations and via notifications so none of the channels falls into a disregard background in which the signals are definitely ignored. Tabuenca et al. \citep{Tabuenca2014} stressed the importance in the timing and content of the notifications to foster reflective practice on meta-learning suggesting sporadic notifications with specific instructions. In this experiment, we have extended their research prompting two notifications per week with messages like LA-09 “ \em Hi Natalia, your colleagues report 53\% of their study-time between 19h and 22h \em ” or LA-08 “ \em Hi Natalia, your colleagues report 33\% of their time on Sundays  \em ” (See Appendix BBBBBBBBBBBBBBBB). Nevertheless, the LA-09 notification was not prompted in the time range between 19h and 22h, nor LA-08 was prompted on a Sunday. Further research is needed to explore whether these notifications trigger reflection episodes leading to better learning performances when the content is directly bound to the personal context of the student (e.g. time, location) in the same moment that the notifications are dispatched.
\begin{itemize}
\item H4. Patterns logging study-time on mobile devices. Findings in this experiment confirm the existence of specific patterns in the way students use personal mobile devices to sample their study-time. 

Daily patterns. The number and the duration of the time-logs presented in figure \ref{fig:sload_10} show that there are two specific time-ranges of the day (09h-15h and 18h-22h) when students are more active. 

Weekly patterns. Thursdays (18.56\%) and Sundays (18.25\%) were the days with more activity in contrast to Mondays (10.56\%) and Fridays (10.69\%) balancing the over-performance from the previous day in a “rebound effect”. 

Timing correlation between signals and samples. Regarding the correlation between the time when the notifications were delivered and the timing of the time-logs, figure \ref{fig:sload_11} shows that the relation cause-effect is clear when notifications were delivered at 20h. Not less remarkable is the effect when the notifications were delivered at 10h (figure \ref{fig:sload_12}) peaking up again just after the delivery time. Additionally, figure \ref{fig:sload_12} shows that the activity just after 20h has remained peaking up probably caused by the continued effect from the previous treatment (See figure \ref{fig:sload_7}). The relation cause-effect between notifications and time-logs is again shown in figure \ref{fig:sload_13}. In this case, the notifications were broadcasted along the day (see red dashed lines) producing more constant number of time-logs (less fluctuations) along the day in contrast to figure \ref{fig:sload_11} and figure \ref{fig:sload_12}. Hence, we conclude that this effect was persistent during the whole time study.

Recording mode patterns. There were more students that preferred to log their time using the synchronous mode of the app (58.43\% of the time-logs. n=534) rather than post-logging with the asynchronous mode (41.57\% of the time-logs. n=380). This preference is probably cause by the fact that synchronous mode ensures more accurate time-logs.

Performance correlation between grades and samples. The results from this experiment show that there seems to be no correlation between the number of time-logs (nor the duration) and the grades obtained in the evaluation at the end of the course. This confirms that time-logging is not an activity for a limited group of students (for example high-achievers) but seems to be useful for all students.

\item H5. Usability of the tools. Based on the measures from the students that participated using the tools to record their study-time for a minimum of 2 months, we have described the importance of providing simple and usable interfaces to integrate mobile support activities in daily routines. The measures of complexity presented in table \ref{tbl:studyload_table11}, the results from the usability test, and the observations of participation and dropouts during the course, confirm that LearnTracker for Android is a suitable interface to log study-time in online environments.
\end{itemize}
\subsection{Limitations}
Most of the conclusions presented in this manuscript are based on the recordings form 13 students taking part in an online university course (C1) during 4 months. The data from courses C2 and C3 was mostly discarded for not being comparable in the duration of the treatments.

Regarding H1, some might argue that the improvements in time-management skills were caused by the simple fact of starting the course. More research is needed contrasting the measures with a control group that would not record time.

Regarding H2 and H3, some of the effects identified in the intermediate measures might be moderated as a consequence of sequencing effects, and not only caused by the treatment delivered during that concrete treatment. More research is needed providing these treatments to separated groups.
\subsection{Significance of the study}
The contribution of this study is fourfold: first, providing empirical results on the effects of sampling study-time using personal mobile devices and providing real time learning analytics from two different channels, namely, notifications and visualizations; second, releasing an open source working platform to facilitate further research on the effects of providing feedback on time devoted to learning in online courses; third, describing specifications and “know how” instructional designers and teacher could implement similar approaches; forth, highlight intriguing research questions for further research in the use of mobile notifications to foster self-regulation.

In future work, we will keep on investigating on these research questions to well as to evaluate how accurate are the time estimations from teachers, how much fluctuates the number and duration of time-logs among students, and whether these time-logs can be used to identify dropouts in a course. We will also extend the framework providing open source and free tools for iOS and web interfaces to facilitate access to all students. 
